{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pickle as pkl\n",
    "import random\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string\n",
    "\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "train = 'data/snli_train.tsv'\n",
    "val = 'data/snli_val.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emb_matrix():\n",
    "    #load fasttext word vectors\n",
    "    words_to_load = 50000\n",
    "\n",
    "    with open('wiki-news-300d-1M-subword.vec') as f:\n",
    "        #remove the first line\n",
    "        firstLine = f.readline()\n",
    "        loaded_embeddings = np.zeros((words_to_load + 2, 300))\n",
    "        words2id = {}\n",
    "        idx2words = {}\n",
    "        #ordered_words = []\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= words_to_load: \n",
    "                break\n",
    "            s = line.split()\n",
    "            loaded_embeddings[i + 2 , :] = np.asarray(s[1:])\n",
    "            words2id['<pad>'] = PAD_IDX\n",
    "            words2id['<unk>'] = UNK_IDX\n",
    "            words2id[s[0]] = i + 2\n",
    "            idx2words[0] = '<pad>'\n",
    "            idx2words[1] = '<unk>'\n",
    "            idx2words[i + 2] = s[0]\n",
    "   \n",
    "\n",
    "    return words2id,idx2words,loaded_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2id,idx2words,loaded_embeddings = load_emb_matrix()\n",
    "\n",
    "pkl.dump(words2id, open(f'data/words2id.pkl', 'wb'))\n",
    "pkl.dump(idx2words, open(f'data/idx2words.pkl', 'wb'))\n",
    "pkl.dump(loaded_embeddings, open(f'data/embedding_matrix.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# lowercase and remove punctuation\n",
    "def tokenize(sent):\n",
    "    tokens = tokenizer(sent)\n",
    "    return [token.text.lower() for token in tokens \n",
    "            if (token.text not in punctuations) & (token.text not in STOP_WORDS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    token_dataset = []\n",
    "    #all_tokens = []\n",
    "    for sample in dataset:\n",
    "        tokens = tokenize(sample)\n",
    "        token_dataset.append(tokens)\n",
    "        #all_tokens += tokens\n",
    "\n",
    "    return token_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens_1 = tokenize_dataset(train_data['sentence1'])\n",
    "train_tokens_2 = tokenize_dataset(train_data['sentence2'])\n",
    "pkl.dump(train_tokens_1, open(\"data/train_data_tokens_1.p\", \"wb\"))\n",
    "pkl.dump(train_tokens_2, open(\"data/train_data_tokens_2.p\", \"wb\"))\n",
    "\n",
    "val_tokens_1 = tokenize_dataset(val_data['sentence1'])\n",
    "val_tokens_2 = tokenize_dataset(val_data['sentence2'])\n",
    "pkl.dump(val_tokens_1, open(\"data/val_data_tokens_1.p\", \"wb\"))\n",
    "pkl.dump(val_tokens_2, open(\"data/val_data_tokens_2.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
